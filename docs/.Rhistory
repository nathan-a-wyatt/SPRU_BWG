install.packages("rmarkdown")
install.packages("knitr")
# Load the necessary packages
library(RCurl)
library(readr)
library(rvest)
station_id <- 161
file_type <- "csv"
# Set years to download
years <- 2016:2019
# Loop through each year and download data
for (year in years) {
# Set start and end dates for the year
start_date <- paste(year, "-01-01", sep = "")
end_date <- paste(year, "-12-31", sep = "")
# Build the URL for the data download
url <- paste0("https://ndawn.ndsu.nodak.edu/get-table.html?station=",
station_id,
"&ttype=hourly&quick_pick=&begin_date=", start_date,
"&end_date=", end_date, "&file_type=", file_type)
# Download the data
data <- getURLContent(url = url, curl = getCurlHandle())
table <- html_table(read_html(data))
# Save the data to a file
filename <- paste("NDAWN_", station_id, "_", year, ".", file_type, sep = "")
write.csv(table[4], filename )
}
# Loop through each year and download data
for (year in years) {
# Set start and end dates for the year
start_date <- paste(year, "-01-01", sep = "")
end_date <- paste(year, "-12-31", sep = "")
# Build the URL for the data download
url <- paste0("https://ndawn.ndsu.nodak.edu/get-table.html?station=",
station_id,
"&ttype=hourly&quick_pick=&begin_date=", start_date,
"&end_date=", end_date, "&file_type=", file_type)
# Download the data
data <- getURLContent(url = url, curl = getCurlHandle())
table <- html_table(read_html(data))
# Save the data to a file
filename <- paste("NDAWN_", station_id, "_", year, ".", file_type, sep = "")
write.csv(table[4], filename )
}
station_id <- 111
# Loop through each year and download data
for (year in years) {
# Set start and end dates for the year
start_date <- paste(year, "-01-01", sep = "")
end_date <- paste(year, "-12-31", sep = "")
# Build the URL for the data download
url <- paste0("https://ndawn.ndsu.nodak.edu/get-table.html?station=",
station_id,
"&ttype=hourly&quick_pick=&begin_date=", start_date,
"&end_date=", end_date, "&file_type=", file_type)
# Download the data
data <- getURLContent(url = url, curl = getCurlHandle())
table <- html_table(read_html(data))
# Save the data to a file
filename <- paste("NDAWN_", station_id, "_", year, ".", file_type, sep = "")
write.csv(table[4], filename )
}
##function for NDAWn
get_NDAWN <- function(stationNum, startYear, stopYear){
years <- startYear:stopYear
station_id <- stationNum
for (year in years) {
# Set start and end dates for the year
start_date <- paste(year, "-01-01", sep = "")
end_date <- paste(year, "-12-31", sep = "")
# Build the URL for the data download
url <- paste0("https://ndawn.ndsu.nodak.edu/get-table.html?station=",
station_id,
"&ttype=hourly&quick_pick=&begin_date=", start_date,
"&end_date=", end_date, "&file_type=", file_type)
# Download the data
data <- getURLContent(url = url, curl = getCurlHandle())
table <- html_table(read_html(data))
# Save the data to a file
filename <- paste("NDAWN_", station_id, "_", year, ".", file_type, sep = "")
write.csv(table[4], filename )
}
}
get_NDAWN(63, 2016, 2022)
setwd("C:/Users/Nathan.Wyatt/OneDrive - USDA/NDAWN")
getwd()
get_NDAWN(63, 2016, 2022)
#read in Sugarbeet NDAWN stations
stations <- read.csv(file = "CLS_weather_stations.csv")
View(stations)
print(station)
for (station in stations$stationNum) {
print(station)
}
for (station in stations$stationNum) {
get_NDAWN(station, 2020, 2021)
}
for (station in stations$stationNum) {
get_NDAWN(station, 2020, 2022)
}
install.packages("DataEditR")
setwd("C:/Users/Nathan.Wyatt/OneDrive - USDA/github_projects/SPRU_BWG/docs")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
getwd()
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv")
View(Fargo2022)
Head(Fargo2022)
head(Fargo2022)
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv", skip = 1, sep = ",", header = True)
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv", skip = 1, sep = ",", header = T)
head(Fargo2022)
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv", skip = 1, sep = ",", header = T, row.names = 1)
head(Fargo2022)
install.packages("DataEditR")
#open up data to edit
DataEditR::data_edit(Fargo2022)
install.packages("janitor")
library(janitor)
get_dupes(Date, Fargo2022$Hour.CST.)
Fargo2022 <- filter(Fargo2022, Date != "Date")
as.data.frame(sapply(Fargo2022,class))
Fargo2022$Date <- lubridate::ymd(Fargo2022$Date)
as.data.frame(sapply(Fargo2022,class))
clean_names(Fargo2022)
January2022 <- Fargo2022 %>% filter(grepl('2022-01-", date))
January2022 <- Fargo2022 %>% filter(grepl('2022-01-', date))
January2022 <- Fargo2022 %>% filter(grepl(2022-01-, date))
January2022 <- Fargo2022 %>% filter(date < 2022-02-01)
January2022 <- Fargo2022 %>% filter(date < '2022-02-01')
Fargo2022 %>% filter(date < '2022-02-01')
Fargo2022 %>% filter(date <= '2022-31-01')
install.packages("tibbletime")
library(tibbletime)
filter_time(Fargo2022, time_formula = '2022-01-01' ~ '2022-01-31')
Fargo2022$Date <- as_tbl_time(Fargo2022$date, index = date)
Fargo2022 <- as_tbl_time(Fargo2022, index = date)
Fargo2022$date <- lubridate::ymd(Fargo2022$date)
January2022 <- Fargo2022 %>% filter(Date < '2022-02-01')
Fargo2022 <- clean_names(Fargo2022)
head(Fargo2022)
Fargo2022$date <- lubridate::ymd(Fargo2022$date)
head(Fargo2022)
January2022 <- Fargo2022 %>% filter(date < '2022-02-01')
ggplot(January2022, aes(x = mean(avg_air_temp_f), y = date)) +
geom_line()
ggplot(January2022, aes(y = mean(avg_air_temp_f), x = date)) +
geom_line()
ggplot(January2022, aes(y = avg_air_temp_f, x = date)) +
geom_point()
ggplot(January2022, aes(y = avg_air_temp_f, x = date)) +
geom_boxplot()
ggplot(January2022, aes(x = date, y = avg_air_temp_f)) +
geom_boxplot()
January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(avg_air_temp_f)) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_boxplot()
January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(avg_air_temp_f))
January2022 %>% group_by(as.Date(date) %>%
summarise(mean_temp = mean(avg_air_temp_f)) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_boxplot()
January2022 %>% group_by(as.Date(date)) %>%
summarise(mean_temp = mean(avg_air_temp_f)) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_boxplot()
January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(avg_air_temp_f))
summarise(mean_temp = mean(as.numerica(avg_air_temp_f))
January2022 %>% group_by(date) %>%
January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(as.numerica(avg_air_temp_f)))
January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(as.numeric(avg_air_temp_f)))
January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(as.numeric(avg_air_temp_f))) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_point() +
geom_line()
Jplot <- January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(as.numeric(avg_air_temp_f))) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_point() +
geom_line()
install.packages("plotly")
install.packages("plotly")
library(plotly)
Jplot <- January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(as.numeric(avg_air_temp_f))) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_point() +
geom_line()
ggplotly(Jplot)
January2022 <- Fargo2022 %>% filter(date < '2022-02-01')
Jplot <- January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(as.numeric(avg_air_temp_f))) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_point() +
geom_line()
ggplotly(Jplot)
#read in the file and label it as "Fargo2022"
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv")
#view the top of the data
head(Fargo2022)
#adding a few options to improve the data and make it Tidy
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv", skip = 1, sep = ",", header = T, row.names = 1)
#quick check data
head(Fargo2022)
Fargo2022 <- clean_names(Fargo2022)
Fargo2022 <- filter(Fargo2022, date != "Date")
as.data.frame(sapply(Fargo2022,class))
Fargo2022$date <- lubridate::ymd(Fargo2022$date)
head(Fargo2022)
#read in the file and label it as "Fargo2022"
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv")
#view the top of the data
head(Fargo2022)
#adding a few options to improve the data and make it Tidy
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv", skip = 1, sep = ",", header = T, row.names = 1)
#quick check data
head(Fargo2022)
Fargo2022 <- clean_names(Fargo2022)
head(Fargo2022)
Fargo2022 <- filter(Fargo2022, date != "Date")
head(Fargo2022)
as.data.frame(sapply(Fargo2022,class))
head(Fargo2022)
#adding a few options to improve the data and make it Tidy
Fargo2022 <- read.csv(file = "data/NDAWN_23_2022.csv", skip = 1, sep = ",", header = T, row.names = 1)
#quick check data
head(Fargo2022)
Fargo2022$date <- lubridate::dmy(Fargo2022$date)
Fargo2022$date <- lubridate::dmy(Fargo2022$date)
head(Fargo2022)
Fargo2022 <- clean_names(Fargo2022)
Fargo2022 <- filter(Fargo2022, date != "Date")
as.data.frame(sapply(Fargo2022,class))
Fargo2022$date <- lubridate::dmy(Fargo2022$date)
head(Fargo2022)
January2022 <- Fargo2022 %>% filter(date < '2022-02-01')
Jplot <- January2022 %>% group_by(date) %>%
summarise(mean_temp = mean(as.numeric(avg_air_temp_f))) %>%
ggplot(aes(x = date, y = mean_temp)) +
geom_point() +
geom_line()
ggplotly(Jplot)
